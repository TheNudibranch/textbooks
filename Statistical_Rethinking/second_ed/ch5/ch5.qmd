---
title: "Rethinking - Chapter 5"
format: 
  html:
    code-fold: show
toc: true
---
```{r}
#| output: false
#| code-fold: true
library(rethinking)
library(dagitty)
```

## 5.0
- Why Multiple Regression:
  1. Control for confounds
  2. Multiple and complex causations - we need the ability to measure mutiple causal effects simultaneously
  3. Interactions

## 5.1 Spurious Association

Data for marriages and divorce rate. Let's plot the priors for mu
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

data(WaffleDivorce)
d <- WaffleDivorce 

d$D <- standardize(d$Divorce)
d$M <- standardize(d$Marriage)
d$A <- standardize(d$MedianAgeMarriage)

m5.1 <- quap(alist(
  D ~ dnorm(mu, sigma),
  mu <- a + bA * A,
  a ~ dnorm(0,0.2),
  bA ~ dnorm(0,0.5),
  sigma ~ dexp(1)
), data=d)

set.seed(10)
prior <- extract.prior(m5.1)

# Only need two points since we only need two points to draw a line
mu <- link(m5.1, post=prior, data=list(A=c(-2,2)))
plot(NULL, xlim=c(-2,2), ylim=c(-2,2))
for (i in 1:50) lines(c(-2,2), mu[i,], col=col.alpha('black', 0.4))
```

Now the posterior:
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

A_seq <- seq(-3,3.2, length.out=30)
mu <- link(m5.1, data=list(A=A_seq))
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI)

plot(D ~ A, data=d, col=rangi2, pch=16)
lines(A_seq, mu.mean, lwd=2)
shade(mu.PI, A_seq)
```

Let's fit the model with marriage as the covariate and look at the coefficients:

```{r}
m5.2 <- quap(alist(
  D ~ dnorm(mu, sigma),
  mu <- a + bM * M,
  a ~ dnorm(0,0.2),
  bM ~ dnorm(0,0.5),
  sigma ~ dexp(1)
), data=d)

precis(m5.1)
precis(m5.2)
```

We see that the magnitude for the coefficient for marriage is lower than that for age, but is an incorrect way to compare models. Or variable importance.

```{r}
#| fig-align: center
dag5.1 <- dagitty('dag{A -> D; A -> M; M -> D}')
coordinates(dag5.1) <- list(x=c(A=0, D=1, M=2), y=c(A=0, D=1, M=0))
drawdag(dag5.1)
```
Model `m5.1` will capture the total effects of "A->D" and "A->M->D", where the second is a mediated effect. Model `m5.2` captures the total effect of "M->D" and "M->A->D", where the second is the back door path.

But, we could also have the DAG there is no direct effect from "M" to "D". In that case, the entire effect observed from the backdoor path: "A->M->D". 
```{r}
#| fig-align: center
dag5.1 <- dagitty('dag{A -> D; A -> M}')
coordinates(dag5.1) <- list(x=c(A=0, D=1, M=2), y=c(A=0, D=1, M=0))
drawdag(dag5.1)
```

So which is the correct DAG? We can use conditional independence. 

- In our first DAG, ever variable is associated with the other, there is no independence without conditioning.
- There are no testable implications in the first DAG

In the second DAG everything is still associated, but if we condition on A, then there is no backdoor pathway from M to D. That is, $M \mathrel{\unicode{x2AEB}} D | A$. 

The `dagitty` package can help deduce these associations:

```{r}
DMA_dag2 <- dagitty('dag{D <- A -> M}')
impliedConditionalIndependencies(DMA_dag2)
```
If we use multiple regression, the coefficients are effect estimates of the given variable on the response, given the other variables in the equation.

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

m5.3 <- quap(alist(
  D ~ dnorm(mu, sigma),
  mu <- a + bM * M + bA * A,
  a ~ dnorm(0,0.2),
  bM ~ dnorm(0,0.5),
  bA ~ dnorm(0,0.5),
  sigma ~ dexp(1)
), data=d)
precis(m5.3)

plot(coeftab(m5.1, m5.2, m5.3), par=c('bA', 'bM'))
```
Notice, $\beta_A$ does not move, it just becomes more uncertain. On the other hand, $\beta_M$ is now overlapping zero. This tests and shows that $M \mathrel{\unicode{x2AEB}} D | A$ is indeed true for the given data generating process. Perhaps DAG 2 is more inline with out DGP. This implies that DAG 1 is out, and marriage has no direct effect on divorce rate.

To help understand the model better, we are going to build 3 types of plots:
1. Residual
2. Posterior Prediction
3. Counterfactual 

For a simple residual plot example, let's look at Age regressed onto Marriage. If we plot this against the Divorce rate, what we see is the relationship between Divorce rate and marriage, when have already accounted for Age.

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

m5.4 <- quap(alist(
  M ~ dnorm(mu, sigma),
  mu <- a +  bAM * A,
  a ~ dnorm(0,0.2),
  bAM ~ dnorm(0,0.5),
  sigma ~ dexp(1)
), data=d)

mu <- link(m5.4)
mu_mean <- colMeans(mu)
mu_resid <- d$M - mu_mean

plot(mu_resid, d$D, pch=16, col=rangi2, main='Residual Plot with Divorce Rate', 
     xlab='Marriage Rate Resid.', ylab='Divorce Rate')
```

Let's do some posterior predictive checks for model `m5.3`:
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

mu <- link(m5.3)

mu_mean <- colMeans(mu)
mu_PI <- apply(mu, 2, PI)

D_sim <- sim(m5.3, n=1e4)
D_PI <- apply(D_sim, 2, PI)

plot(mu_mean ~ d$D, col=rangi2, ylim=range(mu_PI), xlab='Observed Divorce', ylab='Predicted Divorce')
abline(a=0, b=1, lty=2)
for(i in 1:nrow(d)) lines(rep(d$D[i], 2), mu_PI[,i], col=rangi2)
```

Alright, counterfactual time. Basically, if wiggle one part of the DAG, how does it change everything else. For this, we need to build a complete model of our first DAG (where M->D is present). This will allow use to manipulate A and in turn influence M.

```{r}
d <- list()
d$D <- standardize(WaffleDivorce$Divorce)
d$M <- standardize(WaffleDivorce$Marriage)
d$A <- standardize(WaffleDivorce$MedianAgeMarriage)

m5.3_A <- quap(alist(
  ## A -> D <- M
  D ~ dnorm(mu, sigma),
  mu <- a + bM * M + bA * A,
  a ~ dnorm(0,0.2),
  bM ~ dnorm(0,0.5),
  bA ~ dnorm(0,0.5),
  sigma ~ dexp(1),
  
  ## A -> M
  M ~ dnorm(mu_M, sigma_M),
  mu_M <- aM + bAM*A,
  aM ~ dnorm(0,0.2),
  bAM ~ dnorm(0,0.5),
  sigma_M ~ dexp(1)
), data=d)

precis(m5.3_A)
```

Let's manipulate A and see how it propagates through the model. What we see below is the effect of A->D and A->M->D:
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

A_seq <- seq(-2,2,length.out=30)

# `vars` let's us simulate different variables in the model. M is simulated first
# Then D is simulated
s <- sim(m5.3_A, data=list(A=A_seq), vars=c('M', 'D'))

plot(A_seq, colMeans(s$D), ylim=c(-2,2), type='l', xlab='Manipulated A',
     ylab='Counterfactual D')
shade(apply(s$D, 2, PI), A_seq)
mtext('Total Counterfactual effect of A on D')
```

We can also see what we would expect D to be for specific values of A:

```{r}
# Use the mean and sd of WaffleDivorce$MedianAgeMarriage
sim2_dat <- data.frame(A=(c(20,30) - 26.1)/1.24)
s2 <- sim(m5.3_A, data=sim2_dat, vars=c('M', 'D'))

c('Mean'= mean(s2$D[,2] - s2$D[,1]), 'sd'=sd(s2$D[,2] - s2$D[,1]))
```
Now, if we simulate from M, we break the causal link from A->M. So, let's set A=0 (average state) and simulate different values of M:

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

sim_dat <- data.frame(M=seq(-2,2,length.out=30), A=0)
s <- sim(m5.3_A, data=sim_dat, vars='D')

plot(sim_dat$M, colMeans(s), ylim=c(-2,2), type='l', xlab='Manipulated M',
     ylab='Counterfactual D')
shade(apply(s, 2, PI), A_seq)
mtext('Total Counterfactual effect of M on D')
```

Note that in `vars` we don't write A. This because M doesn't influence A.

Just for fun, let's simulate the counterfactuals without the help of `sim`:

```{r}
A_seq <- seq(-2,2,length.out=30)
post <- extract.samples(m5.3_A)

#simulate M values
M_sim <- with(post, {
  vapply(1:30, \(x) rnorm(1e3, aM + bAM*A_seq[x], sigma_M), numeric(1e3))
})

# simluate D values, using M above
D_sim <- with(post, {
  vapply(1:30, \(x) rnorm(1e3, a + bA*A_seq[x] + bM*M_sim[,x], sigma), numeric(1e3))
})
```

