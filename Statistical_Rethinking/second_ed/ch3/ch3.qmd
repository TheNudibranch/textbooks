---
title: "Rethinking - Chapter 3"
format: 
  html:
    code-fold: show
toc: true
---
```{r}
#| output: false
#| code-fold: true
library(rethinking)
```

## 3.0
- Base rate fallacy
- Randomness is a property of information, not of the real world

## 3.1 - Sampling from a grid-approximate posterior
- Use the same globe tossing example as before
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

n_grid <- 1e3
p_grid <- seq(0,1,length.out=n_grid)
prob_p <- rep(1,n_grid)
prob_data <- dbinom(6,9,p_grid)
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)

samps <- sample(p_grid, prob=posterior, size=1e4, replace=T)

par(mfrow=c(1,2))
plot(samps)
dens(samps)
```
- You cannot do `sample(posterior, replace=T)`, this is because the posterior is literally giving the values of $p(\text{param}|\text{data})$, which is not the usual samples we get from mcmc.

## 3.2 Sampling to summarize
- 3 types of questions from these samples
  1. Intervals of defined boundaries
  2. defined probability mass (confidence/credible/comptaible intervals)
  3. questions about point estaimtes

- Get the probability that parameter is below 0.5 using grid as well as samples
```{r}
posterior[p_grid < 0.5] |> sum()
(samps < 0.5) |> mean()
```
- Richard is going to call credible intervals *compatibility intervals*
- What are the boundaries that define some mass of probability (e.g. quantile)
- There are discrepancies between percent interval (PI) and Highest posterior density interval (HPDI)
  - Consider the three water scenario
  - A 50% PI assigns 25% probability at one extreme and 25% probability at the other.
    - Therefore it is finding the central 50% interval
  - The HPDI finds the smallest interval the meets the 50% criteria
    - This includes the most probable values of $p=1$
  
  
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

n_grid <- 1e3
p_grid <- seq(0,1,length.out=n_grid)
prob_p <- rep(1,n_grid)
prob_data <- dbinom(3,3,p_grid)
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)

samps <- sample(p_grid, prob=posterior, size=1e4, replace=T)

pi <- PI(samps, prob=0.5)
x_for_pi_graph <- p_grid[p_grid >= pi[1] & p_grid <= pi[2]]
y_for_pi_graph <- posterior[p_grid >= pi[1] & p_grid <= pi[2]]

hpdi <- HPDI(samps, prob=0.5)
x_for_hpdi_graph <- p_grid[p_grid >= hpdi[1] & p_grid <= hpdi[2]]
y_for_hpdi_graph <- posterior[p_grid >= hpdi[1] & p_grid <= hpdi[2]]

par(mfrow=c(1,2))
plot(p_grid, posterior, type = 'l', lwd=2, main='50% PI')
polygon(c(x_for_pi_graph, rev(x_for_pi_graph)), c(rep(0, length(x_for_pi_graph)), rev(y_for_pi_graph)), col='darkblue')

plot(p_grid, posterior, type = 'l', lwd=2, main='50% HPDI')
polygon(c(x_for_hpdi_graph, rev(x_for_hpdi_graph)), c(rep(0, length(y_for_hpdi_graph)), rev(y_for_hpdi_graph)), col='darkblue')
```

- "If the choice of the interval changes to conclusion, then you are better off plotting the entire posterior"
- Point estimates
  - MAP, mean, and median
  - Use a loss function - different loss functions imply different point summaries
    - We maximize expected winnings (minimize expected loss) when we choose the median
- For a given decisions $p^\prime$, the loss is proportional to $|p^\prime - p|$. 

Thus, $E[|p^\prime - p|] = \int |p^\prime - p| \cdot Pr(p|\text{data}) dp$

Calculated if $p^\prime=0.5$ as:
```{r}
sum(posterior*abs(0.5 - p_grid))
```

We can do all at once with `vapply`:
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

loss <- vapply(p_grid, \(x) sum(posterior*abs(x - p_grid)), numeric(1))
plot(p_grid, loss, type='l', lwd=2)
cat('Median: ', median(samps), 'Lowest loss', p_grid[which.min(loss)])
```
- Absolute loss produces the median, while square loss produces the mean

## 3.3 Sampling to Simulate
- Simulate draws from binomial likelihood with $N=9$ and $p=0.7$
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

dummy_w <- rbinom(1e5, 9, 0.7)
simplehist(dummy_w)
```
- Sampling here is not a physical act, it is a tool that helps use to explore the various distributions we are working with
- Retrodictive checks, not predictive since we already have the data and are seeing how well the model fit our current data
- For this case we can use the conjugate posterior to check exactly so we won't be doing that here

### Posterior Predictive
- We would like to propagate uncertainty from parameter to the implied prediction
- We need to average over the posterior density for $p$ while computing the predictions


Let's try generating some new data, one where we hold $p$ at the median and another wher we allow the uncertainty of the parameter to propagate. Note, this is using the old $W=6, N=9$ samples.

```{r}
#| code-fold: true
n_grid <- 1e3
p_grid <- seq(0,1,length.out=n_grid)
prob_p <- rep(1,n_grid)
prob_data <- dbinom(6,9,p_grid)
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)
samps <- sample(p_grid, prob=posterior, size=1e4, replace=T)
```


```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

par(mfrow=c(1,2))
rbinom(length(samps), size=9, prob=median(samps)) |> simplehist()
rbinom(length(samps), size=9, prob=samps) |> simplehist()
```
The posterior predictive on the right is much wider as it takes into account the parameter uncertainty.

Let's spend some time thinking about what the posterior predictive is, as it will be crucial moving forwad. But first, I need to show you one of the great consequences of working with samples. That is if I have samples $(\alpha, \beta) \sim P(\alpha, \beta)$, I can very easily marginalize over the joint distribution by ignoring one of the parameters. It's crazy, but it actually works. 

That is, if I want plot the marginal distribution of $P(\alpha) = \int P(\alpha, \beta) d\beta$, I can just plot the samples I have just plot the $\alpha$ samples I have from my $(\alpha, \beta)$ samples.

Now, the posterior predictive distribution for data $d$ with parameters $\theta$ is given by $p(\tilde{d}|d) = \int p(\tilde{d}|\theta) p(\theta|d) d\theta$. There is a $d$ hidden in the conditional of $p(\tilde{d}|\theta)$, but it gets dropped since $d$ acts on $\tilde{d}$ through $\theta$ in the generative graph. That is, $d$ and $\tilde{d}$ are conditionally independent give $\theta$. 

We can actually express the integrand as $p(\tilde{d}|\theta,d) p(\theta|d) = p(\tilde{d}, \theta|d)$. We can actually get this joint distribution from something very akin to Gibbs sampling.

Gibbs sampling states that we can obtain samples from the joint distribution $p(\theta_1, \theta_2)$ if we can draw samples from the conditional distributions $p(\theta_2 | \theta_1)$ and $p(\theta_2 | \theta_1)$. We essentaily draw a theta from one of the conditionals, and plug it back into the other, pinging back and forth. For our present case, we are drawing samples from our posterior $p(\theta |d)$ and plugging them into our next conditional $p(\tilde{d}|\theta)$, doing this iteratively produces samples from the joint, where we can then ignore samples for $\theta$ and obtain draws from the posterior predictive $p(\sim{d}|d)$. 

Now, you might have noticed that $p(\theta |d)$ doesn't have $\tilde{d}$ in its conditional. In truth, it doesn't actually matter since $\theta$ is independent of the new data drawn. In the generative graph, there is no information that flows form $\tilde{d}$ back into $\theta$. Thus, we are fine to ignore it when drawing from $p(\theta |d)$, the posterior.

## Excersises
### Set up
```{r}
n <- 1e3
p_grid <- seq(0,1,length.out=n)
prior <- rep(1,length(n))
likelihood <- dbinom(6, 9, prob=p_grid)
post <- likelihood*prior
post <- post / sum(post)
set.seed(100)
samp <- sample(p_grid, prob=post, size=1e4, replace=T)
```

### E.1
- Posterior prob below $p = 0.2$
```{r}
mean(samp <= 0.2)
```
### E.2
- Posterior prob above $p = 0.8$
```{r}
mean(samp >= 0.8)
```
### E.3
- Posterior prob for $p \in [0.2,0.8]$
```{r}
mean(samp >= 0.2 & samp <= 0.8)
```
### M.1
- Redo the experiment except $W=8$ and $N=15$
```{r}
n <- 1e3
p_grid <- seq(0,1,length.out=n)
prior <- rep(1,length(n))
likelihood <- dbinom(8, 15, prob=p_grid)
post <- likelihood*prior
post <- post / sum(post)
set.seed(100)
samp <- sample(p_grid, prob=post, size=1e4, replace=T)
```

### M.2
- Calculate the 90% HPDI
```{r}
HPDI(samp, prob=0.9)
```
### M.3
- Using the posterior predictive, what is the probability of observing 8 waters in 15 tosses
```{r}
post_pred <- rbinom(length(samp), size=15, prob=samp)
mean(post_pred == 8)
```
### M.4
- Using the same samples of $p$, calculate the posterior predictive for 9 tosses and find the probability of 6 waters
```{r}
post_pred <- rbinom(length(samp), size=9, prob=samp)
mean(post_pred == 6)
```
### H.1
- Two vectors of birth data `birth1` and `birth2`
- Use grid approx to get the posterior distribution for the prob of a birth being a boy, assuming a uniform prior
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

data(homeworkch3)

n <- 1e3
p_grid <- seq(0,1,length.out=n)
prior <- rep(1,length(n))
likelihood <- dbinom(sum(c(birth1, birth2)), length(c(birth1, birth2)), prob=p_grid)
post <- likelihood * prior
post <- post/sum(post)
plot(p_grid, post, type='l', lwd=2, main='Posterior for Prob of boy')
```

- Find MAP
```{r}
p_grid[which.max(post)]
```
### H.2
- Sample from the posterior and construct the 50%, 89%, and 97% HPDI
```{r}
samp <- sample(p_grid, 1e4, prob=post, replace=T)
hpdi_50 <- HPDI(samp, prob=0.5)
hpdi_89 <- HPDI(samp, prob=0.89)
hpdi_97 <- HPDI(samp, prob=0.97)
cat(' 50% HPDI: ', hpdi_50, '\n', '89% HPDI: ', hpdi_89, '\n', '97% HPDI: ', hpdi_97, '\n')
```
### H.3
- Get the posterior predictive for 200 births and see how well the model fits
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6

post_pred <- rbinom(length(samp), size=200, prob=samp)
dens(post_pred, lwd=3)
abline(v = sum(birth1, birth2), lwd=2, col='darkred')
legend('topleft', legend=c('Posterior Pred.', 'Actual Count'), lwd=2, col=c('black', 'darkred'))
```
- Looks good!

### H.4
- See how the model compares if our posterior predictive is for 100 births and we compare the `birth1`
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6
post_pred <- rbinom(length(samp), size=100, prob=samp)
dens(post_pred, lwd=3)
abline(v = sum(birth1), lwd=2, col='darkred')
legend('topleft', legend=c('Posterior Pred.', 'Actual Count'), lwd=2, col=c('black', 'darkred'))
```
- Does not look as good. There is something in the data that we are not capturing

### H.5
- How does the model look if we condition on the first birth being a girl
- Does the model adequately capture the pattern observed if we condition on boy or girl in the first birth?

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 6
n_first_girl <- sum(birth1 == 0)
post_pred <- rbinom(length(samp), size=n_first_girl, prob=samp)
dens(post_pred)
abline(v = sum(birth2[birth1 == 0]), lwd=2, col='darkred')
```
- Looks like there is some negative correlation going on in the data
  - That is, if a family had a boy in the first birth, they are more likely to have a girl, and vice versa
- We can quickly see this with a table
```{r}
table(birth1, birth2)
```


